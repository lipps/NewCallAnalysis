"""Streamlitå¯è§†åŒ–Dashboard"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import asyncio
import aiohttp
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import requests

from src.models.schemas import (
    CallAnalysisResult,
    CallInput,
    AnalysisConfig,
    EvidenceHit,
    QuantificationMetrics,
)
from src.utils.logger import get_logger

logger = get_logger(__name__)


class CallAnalysisDashboard:
    """é€šè¯åˆ†æå¯è§†åŒ–Dashboard"""

    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url

    def setup_page(self):
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="é”€å”®é€šè¯è´¨æ£€ç³»ç»Ÿ",
            page_icon="ğŸ“",
            layout="wide",
            initial_sidebar_state="expanded",
        )

        st.title("ğŸ“ é”€å”®é€šè¯è´¨æ£€ç³»ç»Ÿ")
        st.markdown("---")

    def render_sidebar(self) -> Dict[str, Any]:
        """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""
        st.sidebar.header("âš™ï¸ é…ç½®")

        # åˆ†æé…ç½®
        st.sidebar.subheader("åˆ†æè®¾ç½®")
        enable_vector = st.sidebar.checkbox("å¯ç”¨å‘é‡æ£€ç´¢", value=True)
        enable_llm = st.sidebar.checkbox("å¯ç”¨LLMéªŒè¯", value=True)
        confidence_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.7, 0.1)

        # æ˜¾ç¤ºè®¾ç½®
        st.sidebar.subheader("æ˜¾ç¤ºè®¾ç½®")
        show_evidence = st.sidebar.checkbox("æ˜¾ç¤ºè¯æ®ç‰‡æ®µ", value=True)
        show_confidence = st.sidebar.checkbox("æ˜¾ç¤ºç½®ä¿¡åº¦", value=True)

        return {
            "config": AnalysisConfig(
                enable_vector_search=enable_vector,
                enable_llm_validation=enable_llm,
                confidence_threshold=confidence_threshold,
            ),
            "display": {
                "show_evidence": show_evidence,
                "show_confidence": show_confidence,
            },
        }

    def render_input_section(self) -> Optional[Dict[str, Any]]:
        """æ¸²æŸ“è¾“å…¥åŒºåŸŸ"""
        st.header("ğŸ“ é€šè¯æ–‡æœ¬è¾“å…¥")

        # è¾“å…¥æ–¹å¼é€‰æ‹©
        input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["ç›´æ¥è¾“å…¥", "æ–‡ä»¶ä¸Šä¼ ", "ç¤ºä¾‹æ•°æ®"])

        call_data = None

        if input_method == "ç›´æ¥è¾“å…¥":
            call_id = st.text_input(
                "é€šè¯ID", value=f"call_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            transcript = st.text_area(
                "é€šè¯è½¬å†™æ–‡æœ¬", height=200, placeholder="è¯·è¾“å…¥é”€å”®ä¸å®¢æˆ·çš„é€šè¯æ–‡æœ¬..."
            )

            col1, col2 = st.columns(2)
            with col1:
                customer_id = st.text_input("å®¢æˆ·IDï¼ˆå¯é€‰ï¼‰")
            with col2:
                sales_id = st.text_input("é”€å”®å‘˜IDï¼ˆå¯é€‰ï¼‰")

            if transcript.strip():
                call_data = {
                    "call_id": call_id,
                    "transcript": transcript,
                    "customer_id": customer_id or None,
                    "sales_id": sales_id or None,
                    "call_time": datetime.now().isoformat(),
                }

        elif input_method == "æ–‡ä»¶ä¸Šä¼ ":
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶",
                type=["txt", "json"],
                help="æ”¯æŒ.txtæ–‡æœ¬æ–‡ä»¶æˆ–.jsonæ ¼å¼æ–‡ä»¶",
            )

            if uploaded_file:
                try:
                    if uploaded_file.type == "application/json":
                        call_data = json.loads(uploaded_file.read().decode())
                    else:
                        content = uploaded_file.read().decode("utf-8")
                        call_data = {
                            "call_id": f"upload_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                            "transcript": content,
                            "call_time": datetime.now().isoformat(),
                        }
                except Exception as e:
                    st.error(f"æ–‡ä»¶è§£æå¤±è´¥: {e}")

        elif input_method == "ç¤ºä¾‹æ•°æ®":
            example_data = self._get_example_data()
            selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹", list(example_data.keys()))

            if selected_example:
                call_data = example_data[selected_example]
                st.text_area(
                    "ç¤ºä¾‹æ–‡æœ¬é¢„è§ˆ",
                    value=call_data["transcript"][:500] + "...",
                    height=150,
                    disabled=True,
                )

        return call_data

    def _get_example_data(self) -> Dict[str, Dict[str, Any]]:
        """è·å–ç¤ºä¾‹æ•°æ®"""
        return {
            "æˆåŠŸæ¡ˆä¾‹": {
                "call_id": "example_success",
                "transcript": """é”€å”®ï¼šæ‚¨å¥½ï¼Œæˆ‘æ˜¯ç›Šç›Ÿæ“ç›˜æ‰‹çš„ä¸“å‘˜å°ç‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚
å®¢æˆ·ï¼šä½ å¥½ã€‚
é”€å”®ï¼šæ˜¯è¿™æ ·çš„ï¼Œæˆ‘ä»¬æ˜¯è…¾è®¯æŠ•èµ„çš„ä¸Šå¸‚å…¬å¸ï¼Œä¸“é—¨ä¸ºè‚¡æ°‘æä¾›ä¸“ä¸šçš„è‚¡ç¥¨åˆ†ææœåŠ¡ã€‚è€½è¯¯æ‚¨ä¸¤åˆ†é’Ÿæ—¶é—´ï¼Œæˆ‘ç»™æ‚¨å…è´¹è®²è§£ä¸€ä¸‹æˆ‘ä»¬çš„ä¹°å–ç‚¹åŠŸèƒ½ã€‚
å®¢æˆ·ï¼šå¥½çš„ï¼Œä½ è¯´ã€‚
é”€å”®ï¼šå’±ä»¬çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯BSç‚¹æç¤ºï¼ŒBç‚¹ä»£è¡¨æœ€ä½³ä¹°å…¥æ—¶æœºï¼ŒSç‚¹ä»£è¡¨å–å‡ºä¿¡å·ã€‚æ¯”å¦‚æ‚¨æŒæœ‰çš„æ‹›å•†é“¶è¡Œï¼Œæˆ‘ä»¬æ¥å…·ä½“çœ‹ä¸€ä¸‹ã€‚
å®¢æˆ·ï¼šè¿™ä¸ªåŠŸèƒ½å¬èµ·æ¥ä¸é”™ï¼Œæ”¶è´¹å—ï¼Ÿ
é”€å”®ï¼šæ ¹æ®å†å²æ•°æ®ï¼Œä½¿ç”¨æˆ‘ä»¬ä¿¡å·çš„å®¢æˆ·å¹³å‡èƒ½æå‡20%çš„æ”¶ç›Šç‡ã€‚å¦å¤–æˆ‘ä»¬è¿˜æœ‰æ­¥æ­¥é«˜VIPä¸“å±åŠŸèƒ½ã€‚
å®¢æˆ·ï¼šå¯ä»¥è¯•ç”¨ä¸€ä¸‹å—ï¼Ÿ""",
                "customer_id": "customer_001",
                "sales_id": "sales_001",
                "call_time": "2024-01-15T10:30:00",
            },
            "ä¸€èˆ¬æ¡ˆä¾‹": {
                "call_id": "example_normal",
                "transcript": """é”€å”®ï¼šæ‚¨å¥½ï¼Œè¯·é—®æ˜¯ç‹å…ˆç”Ÿå—ï¼Ÿ
å®¢æˆ·ï¼šæ˜¯çš„ï¼Œä»€ä¹ˆäº‹ï¼Ÿ
é”€å”®ï¼šæˆ‘è¿™è¾¹æ˜¯åšè‚¡ç¥¨åˆ†æçš„ï¼Œæƒ³è·Ÿæ‚¨èŠèŠæŠ•èµ„çš„äº‹æƒ…ã€‚
å®¢æˆ·ï¼šä¸éœ€è¦ï¼Œæˆ‘æ²¡ç©ºã€‚
é”€å”®ï¼šä¸ä¼šè€½è¯¯æ‚¨å¤ªä¹…ï¼Œå°±ä¸¤åˆ†é’Ÿã€‚æˆ‘ä»¬æœ‰ä¸ªå¾ˆå¥½çš„ä¹°å–ç‚¹æç¤ºåŠŸèƒ½ã€‚
å®¢æˆ·ï¼šä¸æ„Ÿå…´è¶£ï¼Œè°¢è°¢ã€‚""",
                "customer_id": "customer_002",
                "sales_id": "sales_002",
                "call_time": "2024-01-15T14:20:00",
            },
        }

    def analyze_call(
        self, call_data: Dict[str, Any], config: AnalysisConfig
    ) -> Optional[CallAnalysisResult]:
        """è°ƒç”¨APIåˆ†æé€šè¯"""
        try:
            with st.spinner("æ­£åœ¨åˆ†æé€šè¯..."):
                response = requests.post(
                    f"{self.api_base_url}/analyze",
                    json={"call_input": call_data, "config": config.dict()},
                    timeout=600,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°10åˆ†é’Ÿ
                )

                if response.status_code == 200:
                    result_data = response.json()
                    return CallAnalysisResult(**result_data)
                else:
                    st.error(f"åˆ†æå¤±è´¥: {response.status_code} - {response.text}")
                    return None

        except requests.exceptions.Timeout:
            st.error("è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return None
        except requests.exceptions.ConnectionError:
            st.error("æ— æ³•è¿æ¥åˆ°åˆ†ææœåŠ¡ï¼Œè¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ")
            return None
        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            return None

    def render_results(
        self, result: CallAnalysisResult, display_config: Dict[str, Any]
    ):
        """æ¸²æŸ“åˆ†æç»“æœ"""

        # ç»“æœæ¦‚è§ˆ
        st.header("ğŸ“Š åˆ†æç»“æœ")

        # KPIå¡ç‰‡
        self._render_kpi_cards(result)

        # è¯¦ç»†ç»“æœ
        col1, col2 = st.columns(2)

        with col1:
            self._render_icebreak_results(result.icebreak, display_config)
            self._render_process_metrics(result.process)

        with col2:
            self._render_deduction_results(result, display_config)
            self._render_customer_analysis(result.customer)

        # å®¢æˆ·æ‹’ç»æ²Ÿé€šé¢æ¿ï¼ˆç‹¬ç«‹å±•ç¤ºç»“æ„åŒ–è¾“å‡ºï¼‰
        self._render_rejection_panel(result.icebreak)

        # åŠ¨ä½œæ‰§è¡Œæƒ…å†µ
        self._render_action_execution(result.actions)

        # åŸå§‹æ•°æ®
        with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹JSONæ•°æ®"):
            st.json(result.dict())

    def _render_kpi_cards(self, result: CallAnalysisResult):
        """æ¸²æŸ“KPIå¡ç‰‡"""
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            icebreak_hits = sum(
                1
                for field in [
                    "professional_identity",
                    "value_help",
                    "time_notice",
                    "company_background",
                    "free_teach",
                ]
                if getattr(result.icebreak, field).hit
            )
            st.metric("ç ´å†°å‘½ä¸­ç‡", f"{icebreak_hits}/5", f"{icebreak_hits/5*100:.1f}%")

        with col2:
            # è®¡ç®—æ¼”ç»æ¨¡å—çš„å‘½ä¸­æ•°
            deduction_fields = [
                "bs_explained",
                "period_resonance_explained",
                "control_funds_explained",
                "bubugao_explained",
                "value_quantify_explained",
                "customer_stock_explained",
            ]
            deduction_hits = sum(
                1 for field in deduction_fields
                if getattr(result.æ¼”ç», field).hit
            )

            # åŠ ä¸Šå®¢æˆ·æƒ…å†µè€ƒå¯Ÿçš„å‘½ä¸­æƒ…å†µ
            if result.customer_probing.has_customer_probing:
                deduction_hits += 1
            st.metric(
                "æ¼”ç»è¦†ç›–ç‡", f"{deduction_hits}/7", f"{deduction_hits/7*100:.1f}%"
            )

        with col3:
            st.metric(
                "é€šè¯æ—¶é•¿",
                f"{result.process.explain_duration_min:.1f}åˆ†é’Ÿ",
                "æ­£å¸¸" if 5 <= result.process.explain_duration_min <= 20 else "å¼‚å¸¸",
            )

        with col4:
            st.metric(
                "äº’åŠ¨é¢‘ç‡",
                f"{result.process.interaction_rounds_per_min:.1f}/åˆ†é’Ÿ",
                (
                    "è‰¯å¥½"
                    if 1 <= result.process.interaction_rounds_per_min <= 3
                    else "åä½"
                ),
            )

    def _render_icebreak_results(self, icebreak_data, display_config: Dict[str, Any]):
        """æ¸²æŸ“ç ´å†°ç»“æœ"""
        st.subheader("ğŸ¤ ç ´å†°è¦ç‚¹æ£€æµ‹")

        # ç ´å†°è¦ç‚¹æ•°æ®
        icebreak_points = {
            "ä¸“ä¸šèº«ä»½": icebreak_data.professional_identity,
            "å¸®åŠ©ä»·å€¼": icebreak_data.value_help,
            "æ—¶é—´è¯´æ˜": icebreak_data.time_notice,
            "å…¬å¸èƒŒæ™¯": icebreak_data.company_background,
            "å…è´¹è®²è§£": icebreak_data.free_teach,
        }

        # åˆ›å»ºæ•°æ®æ¡†
        df_data = []
        for point_name, point_data in icebreak_points.items():
            sig = getattr(point_data, "signals", {}) or {}
            df_data.append(
                {
                    "è¦ç‚¹": point_name,
                    "å‘½ä¸­": "âœ…" if point_data.hit else "âŒ",
                    "ç½®ä¿¡åº¦": (
                        f"{point_data.confidence:.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "è¯æ®ç‰‡æ®µ": (
                        point_data.evidence
                        if display_config.get("show_evidence") and point_data.evidence
                        else "-"
                    ),
                    "è¯æ®æ¥æº": getattr(point_data, "evidence_source", "-"),
                    "Rä¿¡": (
                        f"{sig.get('rule_confidence', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Vç›¸": (
                        f"{sig.get('vector_similarity', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Lä¿¡": (
                        f"{sig.get('llm_confidence', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                }
            )

        df = pd.DataFrame(df_data)
        st.dataframe(df, use_container_width=True)

        # é¥¼å›¾
        hit_count = sum(1 for point_data in icebreak_points.values() if point_data.hit)
        miss_count = len(icebreak_points) - hit_count

        fig_pie = px.pie(
            values=[hit_count, miss_count],
            names=["å‘½ä¸­", "æœªå‘½ä¸­"],
            title="ç ´å†°è¦ç‚¹å‘½ä¸­ç‡",
            color_discrete_map={"å‘½ä¸­": "#2E8B57", "æœªå‘½ä¸­": "#DC143C"},
        )
        st.plotly_chart(fig_pie, use_container_width=True)

        # KPI: å®¢æˆ·æ‹’ç»/åº”å¯¹ç­–ç•¥ç»Ÿè®¡
        kpi_col1, kpi_col2 = st.columns(2)
        try:
            if hasattr(icebreak_data, "rejection_kpi") and icebreak_data.rejection_kpi:
                with kpi_col1:
                    st.markdown("**å®¢æˆ·æ‹’ç»-KPI**")
                    total_r = icebreak_data.rejection_kpi.get("total", 0)
                    by_type = icebreak_data.rejection_kpi.get("by_type", [])
                    df_r = pd.DataFrame(by_type)
                    if not df_r.empty:
                        df_r["ratio"] = (df_r["ratio"] * 100).map(lambda x: f"{x:.1f}%")
                    st.metric("æ‹’ç»æ€»æ¬¡æ•°", f"{total_r}")
                    if not df_r.empty:
                        st.dataframe(df_r, use_container_width=True)
                        # é¥¼å›¾ï¼ˆæŒ‰ç±»å‹è®¡æ•°ï¼‰
                        df_r_counts = pd.DataFrame(by_type)
                        df_r_counts = df_r_counts[df_r_counts["count"] > 0]
                        if not df_r_counts.empty:
                            fig_r_pie = px.pie(
                                df_r_counts,
                                values="count",
                                names="type",
                                title="å®¢æˆ·æ‹’ç»-ç±»å‹å æ¯”",
                            )
                            st.plotly_chart(fig_r_pie, use_container_width=True)
                            # æ¡å½¢å›¾ï¼ˆæŒ‰æ¬¡æ•°é™åºï¼‰
                            df_r_counts = df_r_counts.sort_values(
                                "count", ascending=False
                            )
                            fig_r_bar = px.bar(
                                df_r_counts,
                                x="type",
                                y="count",
                                title="å®¢æˆ·æ‹’ç»-ç±»å‹æ¬¡æ•°",
                                text="count",
                            )
                            fig_r_bar.update_layout(
                                xaxis_title="ç±»å‹", yaxis_title="æ¬¡æ•°", showlegend=False
                            )
                            st.plotly_chart(fig_r_bar, use_container_width=True)
            if hasattr(icebreak_data, "handling_kpi") and icebreak_data.handling_kpi:
                with kpi_col2:
                    st.markdown("**åº”å¯¹ç­–ç•¥-KPI**")
                    total_h = icebreak_data.handling_kpi.get("total", 0)
                    by_st = icebreak_data.handling_kpi.get("by_strategy", [])
                    df_h = pd.DataFrame(by_st)
                    if not df_h.empty:
                        df_h["ratio"] = (df_h["ratio"] * 100).map(lambda x: f"{x:.1f}%")
                    st.metric("åº”å¯¹æ€»æ¬¡æ•°", f"{total_h}")
                    if not df_h.empty:
                        st.dataframe(df_h, use_container_width=True)
                        # é¥¼å›¾ï¼ˆæŒ‰ç­–ç•¥è®¡æ•°ï¼‰
                        df_h_counts = pd.DataFrame(by_st)
                        df_h_counts = df_h_counts[df_h_counts["count"] > 0]
                        if not df_h_counts.empty:
                            fig_h_pie = px.pie(
                                df_h_counts,
                                values="count",
                                names="strategy",
                                title="åº”å¯¹ç­–ç•¥-å æ¯”",
                            )
                            st.plotly_chart(fig_h_pie, use_container_width=True)
                            # æ¡å½¢å›¾ï¼ˆæŒ‰æ¬¡æ•°é™åºï¼‰
                            df_h_counts = df_h_counts.sort_values(
                                "count", ascending=False
                            )
                            fig_h_bar = px.bar(
                                df_h_counts,
                                x="strategy",
                                y="count",
                                title="åº”å¯¹ç­–ç•¥-æ¬¡æ•°",
                                text="count",
                            )
                            fig_h_bar.update_layout(
                                xaxis_title="ç­–ç•¥", yaxis_title="æ¬¡æ•°", showlegend=False
                            )
                            st.plotly_chart(fig_h_bar, use_container_width=True)
        except Exception as _:
            pass

    def _render_rejection_panel(self, icebreak_data):
        """æ¸²æŸ“ å®¢æˆ·æ‹’ç»æ²Ÿé€šæƒ…å†µ é¢æ¿"""
        st.subheader("ğŸ™… å®¢æˆ·æ‹’ç»æ²Ÿé€šæƒ…å†µ")
        try:
            count = getattr(icebreak_data, "handle_objection_count", None)
            if count is None:
                # å…¼å®¹æ—§å­—æ®µ
                count = getattr(icebreak_data, "refuse_recover_count", 0)
            st.metric("ä¸šåŠ¡å‘˜åº”å¯¹æ‹’ç»æ¬¡æ•°", f"{count}")

            rr = getattr(icebreak_data, "rejection_reasons", []) or []
            hs = getattr(icebreak_data, "handling_strategies", []) or []

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**å®¢æˆ·æ‹’ç»æ²Ÿé€šåŸå› **")
                if rr:
                    df_rr = pd.DataFrame(rr)
                    # ç»Ÿä¸€åˆ—å
                    if "type" in df_rr.columns and "quote" in df_rr.columns:
                        df_rr = df_rr[["type", "quote"]]
                        df_rr.columns = ["ç±»å‹", "åŸæ–‡ç‰‡æ®µ"]
                    st.dataframe(df_rr, use_container_width=True)
                else:
                    st.info("æœªè¯†åˆ«åˆ°æ˜æ˜¾çš„æ‹’ç»/æŠ—æ‹’è¡¨è¾¾")

            with col2:
                st.markdown("**åº”å¯¹æ‹’ç»çš„åšæ³•**")
                if hs:
                    df_hs = pd.DataFrame(hs)
                    if "strategy" in df_hs.columns and "quote" in df_hs.columns:
                        df_hs = df_hs[["strategy", "quote"]]
                        df_hs.columns = ["ç­–ç•¥", "åŸæ–‡ç‰‡æ®µ"]
                    st.dataframe(df_hs, use_container_width=True)
                else:
                    st.info("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„åº”å¯¹æ‹’ç»åŠ¨ä½œ")
        except Exception as e:
            st.warning(f"æ‹’ç»æ²Ÿé€šé¢æ¿æ¸²æŸ“å¼‚å¸¸: {e}")

    def _render_deduction_results(self, result: CallAnalysisResult, display_config: Dict[str, Any]):
        """æ¸²æŸ“æ¼”ç»ç»“æœ"""
        st.subheader("ğŸ’¡ åŠŸèƒ½æ¼”ç»æ£€æµ‹")

        # åˆ›å»ºå®¢æˆ·æƒ…å†µè€ƒå¯Ÿçš„EvidenceHitæ ¼å¼
        customer_probing_hit = EvidenceHit(
            hit=result.customer_probing.has_customer_probing,
            evidence=result.customer_probing.customer_probing_details[:200] if result.customer_probing.customer_probing_details else "",
            confidence=1.0 if result.customer_probing.has_customer_probing else 0.0,
            evidence_source="llm",
            signals={"llm_confidence": 1.0 if result.customer_probing.has_customer_probing else 0.0}
        )

        # æ¼”ç»è¦ç‚¹æ•°æ®
        deduction_points = {
            "BSç‚¹è®²è§£": result.æ¼”ç».bs_explained,
            "å‘¨æœŸå…±æŒ¯": result.æ¼”ç».period_resonance_explained,
            "æ§ç›˜èµ„é‡‘": result.æ¼”ç».control_funds_explained,
            "æ­¥æ­¥é«˜": result.æ¼”ç».bubugao_explained,
            "ä»·å€¼é‡åŒ–": result.æ¼”ç».value_quantify_explained,
            "æ¼”ç»å®¢æˆ·è‡ªå·±çš„è‚¡ç¥¨": result.æ¼”ç».customer_stock_explained,
            "å®¢æˆ·æƒ…å†µè€ƒå¯Ÿ": customer_probing_hit,
        }

        # åˆ›å»ºæ•°æ®æ¡†
        df_data = []
        for point_name, point_data in deduction_points.items():
            sig = getattr(point_data, "signals", {}) or {}
            df_data.append(
                {
                    "åŠŸèƒ½ç‚¹": point_name,
                    "è®²è§£": "âœ…" if point_data.hit else "âŒ",
                    "ç½®ä¿¡åº¦": (
                        f"{point_data.confidence:.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "è¯æ®ç‰‡æ®µ": (
                        point_data.evidence
                        if display_config.get("show_evidence") and point_data.evidence
                        else "-"
                    ),
                    "è¯æ®æ¥æº": getattr(point_data, "evidence_source", "-"),
                    "Rä¿¡": (
                        f"{sig.get('rule_confidence', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Vç›¸": (
                        f"{sig.get('vector_similarity', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Lä¿¡": (
                        f"{sig.get('llm_confidence', 0):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                }
            )

        # å®‰å…¨åœ°æ·»åŠ ç—›ç‚¹é‡åŒ–æ£€æµ‹
        pain_point_hit = self._create_pain_point_evidence_hit(result)
        if pain_point_hit:
            sig_pp = getattr(pain_point_hit, "signals", {}) or {}
            df_data.append(
                {
                    "åŠŸèƒ½ç‚¹": "ç—›ç‚¹é‡åŒ–æ”¾å¤§",
                    "è®²è§£": "âœ…" if pain_point_hit.hit else "âŒ",
                    "ç½®ä¿¡åº¦": (
                        f"{pain_point_hit.confidence:.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "è¯æ®ç‰‡æ®µ": (
                        pain_point_hit.evidence
                        if display_config.get("show_evidence") and pain_point_hit.evidence
                        else "-"
                    ),
                    "è¯æ®æ¥æº": pain_point_hit.evidence_source,
                    "Rä¿¡": (
                        f"{float(sig_pp.get('rule_confidence', 0.0)):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Vç›¸": (
                        f"{float(sig_pp.get('vector_similarity', 0.0)):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                    "Lä¿¡": (
                        f"{float(sig_pp.get('llm_confidence', 0.0)):.2f}"
                        if display_config.get("show_confidence")
                        else "-"
                    ),
                }
            )

        df = pd.DataFrame(df_data)
        st.dataframe(df, use_container_width=True)

        # æŸ±çŠ¶å›¾ï¼ˆåŒ…å«ç—›ç‚¹é‡åŒ–ï¼‰
        chart_points = list(deduction_points.keys())
        hit_data = [point_data.hit for point_data in deduction_points.values()]

        if pain_point_hit:
            chart_points.append("ç—›ç‚¹é‡åŒ–æ”¾å¤§")
            hit_data.append(pain_point_hit.hit)

        fig_bar = px.bar(
            x=chart_points,
            y=[1 if hit else 0 for hit in hit_data],
            title="åŠŸèƒ½æ¼”ç»è¦†ç›–æƒ…å†µ",
            color=["å·²è®²è§£" if hit else "æœªè®²è§£" for hit in hit_data],
            color_discrete_map={"å·²è®²è§£": "#4CAF50", "æœªè®²è§£": "#F44336"},
        )
        fig_bar.update_layout(showlegend=False)
        st.plotly_chart(fig_bar, use_container_width=True)

        # ç—›ç‚¹é‡åŒ–è¯¦æƒ…é¢æ¿
        self._render_pain_point_details(result)

    def _render_process_metrics(self, process_data):
        """æ¸²æŸ“è¿‡ç¨‹æŒ‡æ ‡"""
        st.subheader("â±ï¸ è¿‡ç¨‹æŒ‡æ ‡")

        col1, col2 = st.columns(2)

        with col1:
            st.metric(
                "è®²è§£æ—¶é•¿",
                f"{process_data.explain_duration_min:.1f} åˆ†é’Ÿ",
                delta=(
                    "æ­£å¸¸" if 5 <= process_data.explain_duration_min <= 20 else "å¼‚å¸¸"
                ),
            )

            st.metric(
                "æ€»å­—æ•°",
                f"{process_data.total_words:,}",
                delta=f"é”€å”®å æ¯” {process_data.sales_words/max(process_data.total_words,1)*100:.1f}%",
            )

        with col2:
            st.metric(
                "äº’åŠ¨é¢‘ç‡",
                f"{process_data.interaction_rounds_per_min:.1f} æ¬¡/åˆ†é’Ÿ",
                delta=(
                    "è‰¯å¥½"
                    if 1 <= process_data.interaction_rounds_per_min <= 3
                    else "åä½"
                ),
            )

            deal_status = "âœ… æˆäº¤/çº¦è®¿" if process_data.deal_or_visit else "âŒ æœªæˆäº¤"
            st.metric("æˆäº¤æƒ…å†µ", deal_status, delta=None)

        # è¦é’±è¡Œä¸ºå±•ç¤º
        with st.expander("ğŸ’° è¦é’±/è´­ä¹°ç±»è¡Œä¸º"):
            count = getattr(process_data, "money_ask_count", 0)
            st.metric("è¦é’±è¡Œä¸ºæ¬¡æ•°", f"{count}")
            quotes = getattr(process_data, "money_ask_quotes", []) or []
            if quotes:
                st.write("**è¯æ®ç‰‡æ®µï¼š**")
                for i, q in enumerate(quotes, 1):
                    st.write(f"{i}. {q}")

    def _render_customer_analysis(self, customer_data):
        """æ¸²æŸ“å®¢æˆ·åˆ†æ"""
        st.subheader("ğŸ‘¤ å®¢æˆ·åˆ†æ")

        # å®¢æˆ·æ€åº¦ - å…¼å®¹å­—ç¬¦ä¸²å’Œå¯¹è±¡ç±»å‹
        try:
            value_recognition = customer_data.value_recognition.value if hasattr(customer_data.value_recognition, 'value') else customer_data.value_recognition
            attitude_color = {"æ˜¯": "success", "å¦": "error", "ä¸æ˜": "warning"}[value_recognition]
            st.write(
                f"**ä»·å€¼è®¤åŒåº¦:** :{attitude_color}[{value_recognition}]"
            )
        except (AttributeError, KeyError) as e:
            logger.warning(f"å®¢æˆ·æ€åº¦æ•°æ®è®¿é—®å¼‚å¸¸: {e}")
            st.write("**ä»·å€¼è®¤åŒåº¦:** æ•°æ®å¼‚å¸¸")

        # æ€åº¦è¯„åˆ†
        st.write(f"**æ€åº¦è¯„åˆ†:** {customer_data.attitude_score:.2f} (-1åˆ°1)")

        # æ€åº¦è¯„åˆ†å¯è§†åŒ–
        fig_gauge = go.Figure(
            go.Indicator(
                mode="gauge+number+delta",
                value=customer_data.attitude_score,
                title={"text": "å®¢æˆ·æ€åº¦è¯„åˆ†"},
                gauge={
                    "axis": {"range": [-1, 1]},
                    "bar": {"color": "darkblue"},
                    "steps": [
                        {"range": [-1, -0.3], "color": "red"},
                        {"range": [-0.3, 0.3], "color": "yellow"},
                        {"range": [0.3, 1], "color": "green"},
                    ],
                    "threshold": {
                        "line": {"color": "black", "width": 4},
                        "thickness": 0.75,
                        "value": 0,
                    },
                },
            )
        )
        fig_gauge.update_layout(height=300)
        st.plotly_chart(fig_gauge, use_container_width=True)

        # å®¢æˆ·æ€»ç»“
        if customer_data.summary:
            st.write(f"**å®¢æˆ·æ€»ç»“:** {customer_data.summary}")

        # å®¢æˆ·é—®é¢˜
        if customer_data.questions:
            st.write("**å®¢æˆ·é—®é¢˜:**")
            for i, question in enumerate(customer_data.questions, 1):
                st.write(f"{i}. {question}")

    def _render_action_execution(self, actions_data):
        """æ¸²æŸ“åŠ¨ä½œæ‰§è¡Œæƒ…å†µ"""
        st.subheader("ğŸ¯ æ ‡å‡†åŠ¨ä½œæ‰§è¡Œæƒ…å†µ")

        # æ”¶é›†æ‰€æœ‰åŠ¨ä½œæ•°æ®
        action_items = [
            ("ä¸“ä¸šèº«ä»½", actions_data.professional_identity),
            ("å¸®åŠ©ä»·å€¼", actions_data.value_help),
            ("æ—¶é—´è¯´æ˜", actions_data.time_notice),
            ("å…¬å¸èƒŒæ™¯", actions_data.company_background),
            ("å…è´¹è®²è§£", actions_data.free_teach),
            ("BSç‚¹è®²è§£", actions_data.bs_explained),
            ("å‘¨æœŸå…±æŒ¯", actions_data.period_resonance_explained),
            ("æ§ç›˜èµ„é‡‘", actions_data.control_funds_explained),
            ("æ­¥æ­¥é«˜", actions_data.bubugao_explained),
            ("ä»·å€¼é‡åŒ–", actions_data.value_quantify_explained),
            ("æ¼”ç»å®¢æˆ·è‡ªå·±çš„è‚¡ç¥¨", actions_data.customer_stock_explained),
        ]

        # åˆ›å»ºæ‰§è¡Œæƒ…å†µè¡¨æ ¼
        df_actions = pd.DataFrame(
            [
                {
                    "åŠ¨ä½œ": name,
                    "æ‰§è¡Œ": "âœ…" if action.executed else "âŒ",
                    "æ¬¡æ•°": action.count,
                    "è¯æ®æ•°é‡": len(action.evidence_list),
                }
                for name, action in action_items
            ]
        )

        st.dataframe(df_actions, use_container_width=True)

        # æ‰§è¡Œç‡ç»Ÿè®¡
        executed_count = sum(1 for _, action in action_items if action.executed)
        total_count = len(action_items)
        execution_rate = executed_count / total_count * 100

        st.metric(
            "æ•´ä½“æ‰§è¡Œç‡", f"{executed_count}/{total_count}", f"{execution_rate:.1f}%"
        )

    def render_batch_analysis(self):
        """æ¸²æŸ“æ‰¹é‡åˆ†æåŠŸèƒ½"""
        st.header("ğŸ“Š æ‰¹é‡åˆ†æ")

        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ‰¹é‡æ–‡ä»¶",
            type=["json", "csv", "txt"],
            accept_multiple_files=True,
            help="æ”¯æŒ JSONã€CSVã€TXT æ‰¹é‡é€šè¯æ•°æ®æ–‡ä»¶ (å•ä¸ªæ–‡ä»¶é™åˆ¶ 200MB)",
        )

        if uploaded_files:
            st.write(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")

            if st.button("å¼€å§‹æ‰¹é‡åˆ†æ"):
                # è¿™é‡Œå®ç°æ‰¹é‡åˆ†æé€»è¾‘
                st.info("æ‰¹é‡åˆ†æåŠŸèƒ½å¼€å‘ä¸­...")

    def run(self):
        """è¿è¡ŒDashboard"""
        self.setup_page()

        # æ¸²æŸ“ä¾§è¾¹æ 
        sidebar_config = self.render_sidebar()

        # ä¸»è¦å†…å®¹åŒºåŸŸ
        tab1, tab2, tab3 = st.tabs(["å•æ¬¡åˆ†æ", "æ‰¹é‡åˆ†æ", "ç³»ç»ŸçŠ¶æ€"])

        with tab1:
            # è¾“å…¥åŒºåŸŸ
            call_data = self.render_input_section()

            # åˆ†ææŒ‰é’®
            if call_data and st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
                result = self.analyze_call(call_data, sidebar_config["config"])
                if result:
                    st.session_state["analysis_result"] = result
                    st.session_state["display_config"] = sidebar_config["display"]

            # æ˜¾ç¤ºç»“æœ
            if "analysis_result" in st.session_state:
                self.render_results(
                    st.session_state["analysis_result"],
                    st.session_state.get("display_config", {}),
                )

        with tab2:
            self.render_batch_analysis()

        with tab3:
            self._render_system_status()

    def _render_system_status(self):
        """æ¸²æŸ“ç³»ç»ŸçŠ¶æ€"""
        st.header("ğŸ–¥ï¸ ç³»ç»ŸçŠ¶æ€")

        try:
            # è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
            response = requests.get(f"{self.api_base_url}/statistics", timeout=10)

            if response.status_code == 200:
                stats = response.json()

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.subheader("å‘é‡å¼•æ“")
                    vector_stats = stats.get("vector_engine", {})
                    st.write(f"æ–‡æ¡£æ•°é‡: {vector_stats.get('document_count', 0)}")
                    st.write(f"ç¼“å­˜å¤§å°: {vector_stats.get('cache_size', 0)}")

                with col2:
                    st.subheader("è§„åˆ™å¼•æ“")
                    rule_stats = stats.get("rule_engine", {})
                    st.write(f"è§„åˆ™æ€»æ•°: {rule_stats.get('total_rules', 0)}")
                    st.write(f"ç¼“å­˜å¤§å°: {rule_stats.get('cache_size', 0)}")

                with col3:
                    st.subheader("LLMå¼•æ“")
                    llm_stats = stats.get("llm_engine", {})
                    st.write(f"è¯·æ±‚æ¬¡æ•°: {llm_stats.get('request_count', 0)}")
                    st.write(f"æ€»Tokenæ•°: {llm_stats.get('total_tokens', 0)}")
                    st.write(f"é”™è¯¯ç‡: {llm_stats.get('error_rate', 0):.2%}")

                # å¥åº·æ£€æŸ¥
                health_response = requests.get(
                    f"{self.api_base_url}/health", timeout=10
                )
                if health_response.status_code == 200:
                    health_data = health_response.json()
                    st.success("âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸")

                    with st.expander("è¯¦ç»†å¥åº·ä¿¡æ¯"):
                        st.json(health_data)
                else:
                    st.error("âŒ ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥")

            else:
                st.error(f"è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {response.status_code}")

        except requests.exceptions.ConnectionError:
            st.error("âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡")
        except Exception as e:
            st.error(f"âŒ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")


    def _create_pain_point_evidence_hit(self, result: CallAnalysisResult) -> Optional[EvidenceHit]:
        """å®‰å…¨åœ°åˆ›å»ºç—›ç‚¹é‡åŒ–è¯æ®å‘½ä¸­å¯¹è±¡"""
        try:
            pq = getattr(result, 'pain_point_quantification', None)
            if not pq:
                return None

            total_score = getattr(pq, 'total_pain_score', 0.0)
            dominant_type = getattr(pq, 'dominant_pain_type', None)
            reliability = getattr(pq, 'quantification_reliability', 0.0)

            if total_score <= 0 or not dominant_type:
                return None

            type_name = dominant_type.value if hasattr(dominant_type, 'value') else str(dominant_type)

            pain_point_mapping = {
                'äºæŸ': getattr(pq, 'loss_pain', None),
                'è¸ç©º': getattr(pq, 'miss_opportunity_pain', None),
                'è¿½é«˜': getattr(pq, 'chase_high_pain', None),
                'å‰²è‚‰': getattr(pq, 'panic_sell_pain', None)
            }
            dominant_hit = pain_point_mapping.get(type_name)

            evidence_text = ""
            dominant_confidence = reliability
            rule_signal = 0.0
            vector_signal = 0.0
            llm_signal = 0.0
            evidence_source = 'pain_point_quantification'

            if dominant_hit:
                try:
                    segments = getattr(dominant_hit, 'evidence_segments', []) or []
                    for seg in segments:
                        if isinstance(seg, str) and seg.strip():
                            evidence_text = seg.strip()
                            break
                    if not evidence_text:
                        evidence_text = getattr(dominant_hit, 'quantification', None)
                        evidence_text = "" if isinstance(evidence_text, QuantificationMetrics) else str(evidence_text or "")
                    dominant_confidence = float(getattr(dominant_hit, 'confidence', reliability) or reliability)
                    signals = getattr(dominant_hit, 'signals', {}) or {}
                    rule_signal = float(signals.get('rule_confidence', 0.0) or 0.0)
                    vector_signal = float(signals.get('vector_similarity', 0.0) or 0.0)
                    llm_signal = float(signals.get('llm_confidence', 0.0) or 0.0)
                    source_candidate = getattr(dominant_hit, 'detection_source', None)
                    if isinstance(source_candidate, str) and source_candidate:
                        evidence_source = source_candidate
                except Exception as err:
                    logger.debug(f"è§£æç—›ç‚¹è¯æ®å¤±è´¥: {err}")

            if not evidence_text:
                logger.warning("ç—›ç‚¹é‡åŒ–å‘½ä¸­ç¼ºå°‘åŸæ–‡è¯æ®ï¼Œæš‚ä¸åœ¨è¡¨æ ¼ä¸­å±•ç¤º")
                return None

            return EvidenceHit(
                hit=True,
                evidence=evidence_text,
                confidence=dominant_confidence,
                evidence_source=evidence_source,
                signals={
                    "total_pain_score": total_score,
                    "quantification_reliability": reliability,
                    "dominant_pain_type": type_name,
                    "rule_confidence": rule_signal,
                    "vector_similarity": vector_signal,
                    "llm_confidence": llm_signal
                }
            )

        except Exception as e:
            logger.error(f"åˆ›å»ºç—›ç‚¹é‡åŒ–è¯æ®æ—¶å‡ºé”™: {e}")
            return None

    def _render_pain_point_details(self, result: CallAnalysisResult):
        """æ¸²æŸ“ç—›ç‚¹é‡åŒ–è¯¦æƒ…é¢æ¿"""
        try:
            # æ£€æŸ¥ç—›ç‚¹é‡åŒ–æ•°æ®æ˜¯å¦å­˜åœ¨
            if not hasattr(result, 'pain_point_quantification') or not result.pain_point_quantification:
                return

            pq = result.pain_point_quantification

            with st.expander("ğŸ” ç—›ç‚¹é‡åŒ–è¯¦æƒ…"):
                # åŸºç¡€ä¿¡æ¯
                total_score = getattr(pq, 'total_pain_score', 0.0)
                dominant_type = getattr(pq, 'dominant_pain_type', None)
                reliability = getattr(pq, 'quantification_reliability', 0.0)

                type_name = 'æ— '
                if dominant_type:
                    try:
                        type_name = dominant_type.value if hasattr(dominant_type, 'value') else str(dominant_type)
                    except AttributeError:
                        type_name = 'æœªè¯†åˆ«'

                st.write(f"**æ€»ç—›ç‚¹è¯„åˆ†:** {total_score:.2f}")
                st.write(f"**ä¸»è¦ç—›ç‚¹ç±»å‹:** {type_name}")
                st.write(f"**é‡åŒ–å¯ä¿¡åº¦:** {reliability:.2f}")

                # å„ç±»ç—›ç‚¹è¯¦æƒ…
                pain_types = [
                    ('äºæŸ', getattr(pq, 'loss_pain', None)),
                    ('è¸ç©º', getattr(pq, 'miss_opportunity_pain', None)),
                    ('è¿½é«˜', getattr(pq, 'chase_high_pain', None)),
                    ('å‰²è‚‰', getattr(pq, 'panic_sell_pain', None))
                ]

                pain_df_data = []
                for name, pain_point in pain_types:
                    if pain_point is None:
                        continue

                    try:
                        detected = getattr(pain_point, 'detected', False)
                        confidence = getattr(pain_point, 'confidence', 0.0)
                        quantification = getattr(pain_point, 'quantification', None)

                        if quantification:
                            amount = getattr(quantification, 'amount', None)
                            frequency = getattr(quantification, 'frequency', None)
                            ratio = getattr(quantification, 'ratio', None)
                            severity_score = getattr(quantification, 'severity_score', 0.0)

                            amount_str = f"{amount} ä¸‡å…ƒ" if amount is not None else "æ— "
                            frequency_str = f"{frequency} æ¬¡" if frequency is not None else "æ— "
                            ratio_str = f"{(ratio * 100):.2f}%" if ratio is not None else "æ— "
                        else:
                            amount_str = frequency_str = ratio_str = "æ— "
                            severity_score = 0.0

                        pain_df_data.append({
                            "ç—›ç‚¹ç±»å‹": name,
                            "æ˜¯å¦æ£€æµ‹åˆ°": "âœ…" if detected else "âŒ",
                            "ç½®ä¿¡åº¦": f"{confidence:.2f}",
                            "é‡‘é¢é‡åŒ–": amount_str,
                            "é¢‘æ¬¡é‡åŒ–": frequency_str,
                            "æ¯”ä¾‹é‡åŒ–": ratio_str,
                            "ä¸¥é‡ç¨‹åº¦": f"{severity_score:.2f}"
                        })
                    except Exception as e:
                        logger.warning(f"å¤„ç†ç—›ç‚¹ {name} æ—¶å‡ºé”™: {e}")
                        continue

                if pain_df_data:
                    pain_df = pd.DataFrame(pain_df_data)
                    st.dataframe(pain_df, use_container_width=True)
                else:
                    st.info("æš‚æ— ç—›ç‚¹é‡åŒ–æ•°æ®")

        except Exception as e:
            logger.error(f"æ¸²æŸ“ç—›ç‚¹é‡åŒ–è¯¦æƒ…æ—¶å‡ºé”™: {e}")
            st.warning("ç—›ç‚¹é‡åŒ–è¯¦æƒ…æ˜¾ç¤ºå¼‚å¸¸")


def main():
    """ä¸»å‡½æ•°"""
    dashboard = CallAnalysisDashboard()
    dashboard.run()


if __name__ == "__main__":
    main()
